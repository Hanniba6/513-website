{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3444f23f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91d3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4dcc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfbba2f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c9bc5d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f12c91d9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6d2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)  # Fixed: Correct rcParams syntax\n",
    "\n",
    "# Import data\n",
    "try:\n",
    "    # Try to read CSV file\n",
    "    df = pd.read_csv('churn_data.csv')\n",
    "    print(\"Data imported successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(\"\\nFirst 5 rows of data:\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    # If file doesn't exist, generate synthetic data\n",
    "    print(\"churn_data.csv not found, generating synthetic data...\")\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Generate synthetic data\n",
    "    n_customers = 100\n",
    "    customer_emails = [f\"customer{i}@example.com\" for i in range(1, n_customers + 1)]\n",
    "    months_as_customer = np.random.randint(1, 36, n_customers)\n",
    "    order_count = np.random.randint(0, 10, n_customers)\n",
    "\n",
    "    # Generate days since last order, correlated with customer activity\n",
    "    days_since_last_order = []\n",
    "    for i in range(n_customers):\n",
    "        # Older customers with more orders are more likely to have recent purchases\n",
    "        if months_as_customer[i] > 12 and order_count[i] > 3:\n",
    "            days = np.random.randint(1, 60)\n",
    "        elif months_as_customer[i] > 6 or order_count[i] > 1:\n",
    "            days = np.random.randint(30, 120)\n",
    "        else:\n",
    "            days = np.random.randint(60, 180)\n",
    "        days_since_last_order.append(days)\n",
    "\n",
    "    # Define churn label: churned if no purchase for >90 days\n",
    "    churned = [1 if days > 90 else 0 for days in days_since_last_order]\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'customer_email': customer_emails,\n",
    "        'months_as_customer': months_as_customer,\n",
    "        'order_count': order_count,\n",
    "        'days_since_last_order': days_since_last_order,\n",
    "        'churned': churned\n",
    "    })\n",
    "\n",
    "    # Save synthetic data to CSV\n",
    "    df.to_csv('churn_data.csv', index=False)\n",
    "    print(\"Synthetic data generated and saved as churn_data.csv\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(\"\\nFirst 5 rows of data:\")\n",
    "    print(df.head())\n",
    "\n",
    "# Data preprocessing\n",
    "print(\"\\nData preprocessing...\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing value check:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# If there are missing values, fill them\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    df = df.fillna({\n",
    "        'months_as_customer': df['months_as_customer'].median(),\n",
    "        'order_count': df['order_count'].median(),\n",
    "        'days_since_last_order': df['days_since_last_order'].median()\n",
    "    })\n",
    "    print(\"Missing values have been filled\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# View target variable distribution\n",
    "print(\"\\nChurn distribution:\")\n",
    "print(df['churned'].value_counts())\n",
    "print(f\"Churn rate: {df['churned'].mean():.2%}\")  # Fixed: Correct percentage formatting\n",
    "\n",
    "# Visualize target variable distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='churned', data=df)\n",
    "plt.title('Customer Churn Distribution')\n",
    "plt.xlabel('Churn Status (0=Active, 1=Churned)')\n",
    "plt.ylabel('Number of Customers')  # Fixed: Correct ylabel syntax\n",
    "plt.xticks([0, 1], ['Active', 'Churned'])  # Fixed: Correct xticks syntax\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d89eb3",
   "metadata": {},
   "source": [
    "Part 3: Feature Analysis and Visualization (Error-Free Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation analysis\n",
    "print(\"\\nFeature correlation analysis:\")\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df.drop('customer_email', axis=1).corr()\n",
    "\n",
    "# Visualize correlation heatmap (Fixed all syntax errors)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    fmt='.2f',  # Fixed: Correct decimal formatting\n",
    "    linewidths=0.5  # Fixed: Clear decimal for line width\n",
    ")\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Analyze relationship between each feature and churn\n",
    "\n",
    "# 1. Customer tenure vs churn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='churned', y='months_as_customer', data=df)\n",
    "plt.title('Customer Tenure vs Churn')\n",
    "plt.xlabel('Churn Status (0=Active, 1=Churned)')\n",
    "plt.ylabel('Months as Customer')  # Fixed\n",
    "plt.xticks([0, 1], ['Active', 'Churned'])  # Fixed\n",
    "plt.show()\n",
    "\n",
    "# 2. Order count vs churn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='churned', y='order_count', data=df)\n",
    "plt.title('Order Count vs Churn')\n",
    "plt.xlabel('Churn Status (0=Active, 1=Churned)')\n",
    "plt.ylabel('Number of Orders')  # Fixed\n",
    "plt.xticks([0, 1], ['Active', 'Churned'])  # Fixed\n",
    "plt.show()\n",
    "\n",
    "# 3. Days since last order vs churn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='churned', y='days_since_last_order', data=df)\n",
    "plt.title('Days Since Last Order vs Churn')\n",
    "plt.xlabel('Churn Status (0=Active, 1=Churned)')\n",
    "plt.ylabel('Days Since Last Order')  # Fixed\n",
    "plt.xticks([0, 1], ['Active', 'Churned'])  # Fixed\n",
    "plt.show()\n",
    "\n",
    "# Create feature distribution plots\n",
    "features = ['months_as_customer', 'order_count', 'days_since_last_order']\n",
    "\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Left plot: Distribution by churn status\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df, x=feature, hue='churned', kde=True, element='step')\n",
    "    plt.title(f'{feature.replace(\"_\", \" \").title()} Distribution by Churn')\n",
    "    plt.xlabel(feature.replace(\"_\", \" \").title())\n",
    "    plt.ylabel('Count')  # Fixed\n",
    "\n",
    "    # Right plot: KDE plot by churn status\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.kdeplot(df[df['churned'] == 0][feature], label='Active', fill=True)\n",
    "    sns.kdeplot(df[df['churned'] == 1][feature], label='Churned', fill=True)\n",
    "    plt.title(f'{feature.replace(\"_\", \" \").title()} Density by Churn')\n",
    "    plt.xlabel(feature.replace(\"_\", \" \").title())\n",
    "    plt.ylabel('Density')  # Fixed\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39da10e",
   "metadata": {},
   "source": [
    "Part 4: Model Building and Training (Error-Free Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d8c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target variable\n",
    "print(\"\\nPreparing data for model training...\")\n",
    "\n",
    "# Features (X) - use only the numeric features\n",
    "X = df[['months_as_customer', 'order_count', 'days_since_last_order']]\n",
    "\n",
    "# Target (y)\n",
    "y = df['churned']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,  # Fixed: Clear decimal\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build and train the logistic regression model\n",
    "print(\"\\nBuilding and training the logistic regression model...\")\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Model coefficients and intercept\n",
    "print(\"\\nModel coefficients:\")\n",
    "feature_names = X.columns\n",
    "for i, (feature, coef) in enumerate(zip(feature_names, model.coef_[0])):\n",
    "    print(f\"{feature}: {coef:.4f}\")\n",
    "print(f\"Intercept: {model.intercept_[0]:.4f}\")  # Fixed: Consistent formatting\n",
    "\n",
    "# Feature importance visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_importance = np.abs(model.coef_[0])\n",
    "sns.barplot(x=feature_names, y=feature_importance)\n",
    "plt.title('Feature Importance in Churn Prediction')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance (Absolute Coefficient Value)')  # Fixed\n",
    "plt.xticks(rotation=45)  # Fixed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2e6b1",
   "metadata": {},
   "source": [
    "Part 5: Model Evaluation (Error-Free Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "print(\"\\nMaking predictions on test data...\")\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"\\nModel evaluation:\")\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix (Fixed all syntax errors)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=['Predicted Active', 'Predicted Churned'],\n",
    "    yticklabels=['Actual Active', 'Actual Churned']\n",
    ")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')  # Fixed (critical correction)\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate additional metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nAdditional Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# ROC Curve (Fixed all syntax errors)\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, label=f'Logistic Regression (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])  # Fixed: Correct decimal formatting\n",
    "plt.ylim([0.0, 1.05])  # Fixed: Correct decimal formatting\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')  # Fixed\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve (Fixed all syntax errors)\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_proba)  # Renamed to avoid conflict\n",
    "avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall_vals, precision_vals, label=f'Logistic Regression (AP = {avg_precision:.3f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')  # Fixed\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a15a5c3",
   "metadata": {},
   "source": [
    "Part 6: Making Predictions for New Customers (Error-Free Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to predict churn for new customers\n",
    "def predict_churn(customer_data, model, scaler):\n",
    "    \"\"\"\n",
    "    Predict churn probability for new customer data\n",
    "\n",
    "    Parameters:\n",
    "    customer_data (dict or DataFrame): Customer features\n",
    "    model: Trained logistic regression model\n",
    "    scaler: Fitted StandardScaler\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Prediction results\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame if it's a dictionary\n",
    "    if isinstance(customer_data, dict):\n",
    "        df_new = pd.DataFrame([customer_data])  # Renamed to avoid conflict with global df\n",
    "    else:\n",
    "        df_new = customer_data\n",
    "\n",
    "    # Select features\n",
    "    X_new = df_new[['months_as_customer', 'order_count', 'days_since_last_order']]\n",
    "\n",
    "    # Scale features\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "    # Make predictions\n",
    "    churn_prob = model.predict_proba(X_new_scaled)[:, 1]\n",
    "    churn_pred = model.predict(X_new_scaled)\n",
    "\n",
    "    # Add predictions to DataFrame\n",
    "    results = df_new.copy()\n",
    "    results['churn_probability'] = churn_prob\n",
    "    results['churn_prediction'] = churn_pred\n",
    "    results['churn_risk'] = pd.cut(\n",
    "        churn_prob,\n",
    "        bins=[0, 0.3, 0.7, 1],  # Fixed: Clear decimals\n",
    "        labels=['Low', 'Medium', 'High']\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example 1: Predict for a single new customer\n",
    "print(\"\\nExample 1: Predicting churn for a single new customer\")\n",
    "new_customer = {\n",
    "    'customer_email': 'new_customer@example.com',\n",
    "    'months_as_customer': 3,\n",
    "    'order_count': 1,\n",
    "    'days_since_last_order': 75\n",
    "}\n",
    "\n",
    "prediction = predict_churn(new_customer, model, scaler)\n",
    "print(prediction[['customer_email', 'churn_probability', 'churn_prediction', 'churn_risk']])\n",
    "\n",
    "# Example 2: Predict for multiple new customers\n",
    "print(\"\\nExample 2: Predicting churn for multiple new customers\")\n",
    "new_customers = pd.DataFrame([\n",
    "    {\n",
    "        'customer_email': 'customer1@example.com',\n",
    "        'months_as_customer': 12,\n",
    "        'order_count': 5,\n",
    "        'days_since_last_order': 30\n",
    "    },\n",
    "    {\n",
    "        'customer_email': 'customer2@example.com',\n",
    "        'months_as_customer': 2,\n",
    "        'order_count': 1,\n",
    "        'days_since_last_order': 100\n",
    "    },\n",
    "    {\n",
    "        'customer_email': 'customer3@example.com',\n",
    "        'months_as_customer': 6,\n",
    "        'order_count': 2,\n",
    "        'days_since_last_order': 45\n",
    "    }\n",
    "])\n",
    "\n",
    "predictions = predict_churn(new_customers, model, scaler)\n",
    "print(predictions[['customer_email', 'churn_probability', 'churn_prediction', 'churn_risk']])\n",
    "\n",
    "# Example 3: Identify high-risk customers from the test set\n",
    "print(\"\\nExample 3: Identifying high-risk customers from the test set\")\n",
    "test_customers = pd.DataFrame(X_test, columns=X.columns)\n",
    "test_customers['customer_email'] = df.loc[X_test.index, 'customer_email'].values\n",
    "\n",
    "test_predictions = predict_churn(test_customers, model, scaler)\n",
    "high_risk = test_predictions[test_predictions['churn_risk'] == 'High']\n",
    "\n",
    "print(f\"Number of high-risk customers in test set: {len(high_risk)}\")\n",
    "if len(high_risk) > 0:\n",
    "    print(\"\\nHigh-risk customers:\")\n",
    "    print(high_risk[['customer_email', 'churn_probability', 'months_as_customer', 'order_count', 'days_since_last_order']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1510fa5d",
   "metadata": {},
   "source": [
    "Part 7: Model Deployment Preparation (Error-Free Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00700bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and scaler for deployment\n",
    "import joblib\n",
    "\n",
    "print(\"\\nSaving model and scaler for deployment...\")\n",
    "\n",
    "# Create a dictionary with all necessary components\n",
    "model_components = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'feature_names': X.columns.tolist(),\n",
    "    'description': 'Customer churn prediction model using logistic regression',\n",
    "    'version': '1.0',  # Fixed: Clear decimal for version\n",
    "    'created_at': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "# Save to a file\n",
    "joblib.dump(model_components, 'churn_model.pkl')\n",
    "print(\"Model components saved to churn_model.pkl\")\n",
    "\n",
    "# Example of how to load the model in a production environment\n",
    "print(\"\\nExample: Loading the model for inference\")\n",
    "loaded_components = joblib.load('churn_model.pkl')\n",
    "loaded_model = loaded_components['model']\n",
    "loaded_scaler = loaded_components['scaler']\n",
    "\n",
    "# Verify the loaded model works\n",
    "verification_prediction = predict_churn(new_customer, loaded_model, loaded_scaler)\n",
    "print(\"Verification prediction with loaded model:\")\n",
    "print(verification_prediction[['customer_email', 'churn_probability', 'churn_prediction', 'churn_risk']])\n",
    "\n",
    "# Create a simple inference function that could be used in a web application\n",
    "def churn_inference_api(customer_data):\n",
    "    \"\"\"\n",
    "    API function for churn prediction\n",
    "\n",
    "    Parameters:\n",
    "    customer_data (dict): Customer features\n",
    "\n",
    "    Returns:\n",
    "    dict: Prediction results\n",
    "    \"\"\"\n",
    "    # Load model components\n",
    "    components = joblib.load('churn_model.pkl')\n",
    "    model = components['model']\n",
    "    scaler = components['scaler']\n",
    "\n",
    "    # Convert input to DataFrame\n",
    "    df_api = pd.DataFrame([customer_data])  # Renamed to avoid conflict\n",
    "\n",
    "    # Make prediction\n",
    "    result = predict_churn(df_api, model, scaler)\n",
    "\n",
    "    # Convert to dictionary for API response\n",
    "    response = {\n",
    "        'customer_email': result['customer_email'].iloc[0],\n",
    "        'churn_probability': float(result['churn_probability'].iloc[0]),\n",
    "        'churn_prediction': int(result['churn_prediction'].iloc[0]),\n",
    "        'churn_risk': result['churn_risk'].iloc[0],\n",
    "        'model_version': components['version'],\n",
    "        'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "\n",
    "    return response\n",
    "\n",
    "# Test the API function\n",
    "print(\"\\nTesting the inference API function:\")\n",
    "api_response = churn_inference_api(new_customer)\n",
    "print(api_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922e27f",
   "metadata": {},
   "source": [
    "Part 8: Conclusion and Next Steps (Error-Free Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of findings and recommendations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"1. Feature Importance:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': np.abs(model.coef_[0])\n",
    "}).sort_values('Importance', ascending=False)\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "print(\"\\n2. Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\n3. Customer Segmentation:\")\n",
    "# Segment customers based on predicted risk\n",
    "test_predictions = predict_churn(pd.DataFrame(X_test, columns=X.columns), model, scaler)\n",
    "test_predictions['customer_email'] = df.loc[X_test.index, 'customer_email'].values\n",
    "\n",
    "risk_segments = test_predictions['churn_risk'].value_counts()\n",
    "print(f\"Low-risk customers: {risk_segments.get('Low', 0)} ({risk_segments.get('Low', 0)/len(test_predictions):.1%})\")\n",
    "print(f\"Medium-risk customers: {risk_segments.get('Medium', 0)} ({risk_segments.get('Medium', 0)/len(test_predictions):.1%})\")\n",
    "print(f\"High-risk customers: {risk_segments.get('High', 0)} ({risk_segments.get('High', 0)/len(test_predictions):.1%})\")\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "print(\"1. For high-risk customers:\")\n",
    "print(\"   - Implement immediate retention campaigns (discounts, personalized offers)\")\n",
    "print(\"   - Increase customer support outreach\")\n",
    "print(\"   - Analyze why they haven't purchased recently\")\n",
    "\n",
    "print(\"\\n2. For medium-risk customers:\")\n",
    "print(\"   - Send targeted marketing emails with relevant product recommendations\")\n",
    "print(\"   - Implement loyalty programs to encourage repeat purchases\")\n",
    "print(\"   - Monitor their activity closely\")\n",
    "\n",
    "print(\"\\n3. For low-risk customers:\")\n",
    "print(\"   - Focus on upselling and cross-selling opportunities\")\n",
    "print(\"   - Request reviews and referrals\")\n",
    "print(\"   - Maintain regular communication\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Model Improvement:\")\n",
    "print(\"   - Collect additional features (e.g., average order value, product categories)\")\n",
    "print(\"   - Try other algorithms (random forest, gradient boosting)\")\n",
    "print(\"   - Implement hyperparameter tuning\")\n",
    "\n",
    "print(\"\\n2. Deployment:\")\n",
    "print(\"   - Integrate the model with your e-commerce platform\")\n",
    "print(\"   - Set up automated prediction pipelines\")\n",
    "print(\"   - Create a dashboard for customer retention teams\")\n",
    "\n",
    "print(\"\\n3. Monitoring and Evaluation:\")\n",
    "print(\"   - Track model performance over time\")\n",
    "print(\"   - Implement A/B testing for retention strategies\")\n",
    "print(\"   - Regularly update the model with new data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXERCISE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chuan_Python1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
